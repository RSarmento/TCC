{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 2.7.15+ (default, Nov 27 2018, 23:36:35) \n",
      "[GCC 7.3.0]\n",
      "NLTK: 3.2.5\n",
      "Scikit-learn: 0.20.3\n",
      "Pandas: 0.24.2\n",
      "Numpy: 1.14.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 2 columns):\n",
      "0    793 non-null object\n",
      "1    793 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.5+ KB\n",
      "None\n",
      "                  0                                                  1\n",
      "0     mand seguranc  inexecuca contrat sanca afast reexam prov clau...\n",
      "1     respons civil  acident aer decretol n dol eventual respons at...\n",
      "2  processual civil  intimaca art cpc irregular nao comprov recurs ...\n",
      "3     process civil  honorari execuca legitim part superior tribuna...\n",
      "4         administr  servidor public artig lei n artig lei n revoga...\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/dataset_classes.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processual civil                             223\n",
      "agrav regimental                             106\n",
      "tributari                                     68\n",
      "hab corpus                                    59\n",
      "embarg declaraca                              48\n",
      "process civil                                 47\n",
      "administr                                     45\n",
      "recurs especial                               25\n",
      "previdenciari                                 13\n",
      "recurs ordinari                               13\n",
      "agrav intern                                   9\n",
      "processual penal                               9\n",
      "embarg declaratori                             8\n",
      "penal                                          8\n",
      "embarg divergenc                               7\n",
      "conflit negat competenc                        6\n",
      "process penal                                  5\n",
      "direit administr                               5\n",
      "processual                                     5\n",
      "execuca fiscal                                 5\n",
      "civil                                          4\n",
      "conflit competenc                              4\n",
      "mand seguranc                                  3\n",
      "estatut crianc                                 2\n",
      "recurs                                         2\n",
      "aca rescisor                                   2\n",
      "agrav instrument                               2\n",
      "med cautel                                     2\n",
      "contrat bancari                                2\n",
      "respons civil                                  2\n",
      "                                            ... \n",
      "ement processual civil embarg declaratori      1\n",
      "aca improb administr                           1\n",
      "ement cobranc                                  1\n",
      "ir                                             1\n",
      "direit comercial                               1\n",
      "requisica pequen valor                         1\n",
      "aca civil public                               1\n",
      "deposit judic                                  1\n",
      "consorci                                       1\n",
      "execuca penal                                  1\n",
      "iptu progress                                  1\n",
      "desapropriaca util public                      1\n",
      "alvar                                          1\n",
      "direit penal                                   1\n",
      "sindicat                                       1\n",
      "transport intermunicipal                       1\n",
      "cooper credit                                  1\n",
      "chequ                                          1\n",
      "aca indenizaca                                 1\n",
      "petica receb hab corpus                        1\n",
      "plan saud                                      1\n",
      "agrav regiment                                 1\n",
      "direit processual civil                        1\n",
      "servic implantaca                              1\n",
      "contribuica incra                              1\n",
      "ped reconsideraca apresent praz recursal       1\n",
      "embarg declaraca receb agrav regimental        1\n",
      "ement agrav regimental                         1\n",
      "servic telefon                                 1\n",
      "agrav regimental embarg declaraca              1\n",
      "Name: 0, Length: 82, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 75 65 62  4 48 58 55 80 79]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes\n",
    "encoder = LabelEncoder()\n",
    "classes = encoder.fit_transform(classes)\n",
    "\n",
    "print(classes[:10])\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    inexecuca contrat sanca afast reexam prov clau...\n",
      "1    acident aer decretol n dol eventual respons at...\n",
      "2    intimaca art cpc irregular nao comprov recurs ...\n",
      "3    honorari execuca legitim part superior tribuna...\n",
      "4    servidor public artig lei n artig lei n revoga...\n",
      "5    iss arrend mercantil incidenc mat constitucion...\n",
      "6    processual penal art codig process penal conhe...\n",
      "7    recurs especial art incis art ambos codig pena...\n",
      "8    praz prescricional lei complement n artig lei ...\n",
      "9    licitaca aca anulator indefer tutel antecip ag...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3410, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# uso de word2vec para a extração de features\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ementas_list = [word for word in ementas.iteritems()]\n",
    "ementas_list_list = []\n",
    "for doc in ementas_list:\n",
    "    ementas_list_list.append(doc[1].split())\n",
    "\n",
    "X = Word2Vec(ementas_list_list, min_count=2)\n",
    "X.wv.init_sims() # para inicializar model.vw.syn0norm, necessário para o cálculo da média da\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções para calcular a média vetorial das palavras de cada ementa\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para tokenizar as palavras com frequência maior que 2\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14434595  0.02304993  0.04989565 ... -0.07615176  0.02941636\n",
      "  -0.04480303]\n",
      " [ 0.12452289  0.03159952  0.05815442 ... -0.06920306  0.03524349\n",
      "  -0.02274381]\n",
      " [ 0.13089664  0.0446075   0.05487002 ... -0.0810603   0.03045238\n",
      "  -0.0177536 ]\n",
      " ...\n",
      " [ 0.13796405  0.02995665  0.05505783 ... -0.07377195  0.02984725\n",
      "  -0.04124976]\n",
      " [ 0.1385827   0.04720109  0.04975444 ... -0.07616398  0.04028198\n",
      "  -0.03079266]\n",
      " [ 0.13406566  0.02936492  0.05563158 ... -0.07149168  0.03391809\n",
      "  -0.03358595]]\n",
      "[[ 0.13541737  0.04342233  0.05166049 ... -0.07384245  0.0387635\n",
      "  -0.03114915]\n",
      " [ 0.1759237  -0.00786242  0.03587133 ... -0.09030756  0.02455668\n",
      "  -0.06454533]\n",
      " [ 0.11141677  0.04794783  0.06108342 ... -0.06697238  0.03304423\n",
      "  -0.01333338]\n",
      " ...\n",
      " [ 0.12622513  0.0354398   0.05465707 ... -0.07477427  0.03180372\n",
      "  -0.01997102]\n",
      " [ 0.12316269  0.03934731  0.06462952 ... -0.05892854  0.04340352\n",
      "  -0.03298957]\n",
      " [ 0.16833887 -0.00659573  0.0352239  ... -0.09245081  0.02598402\n",
      "  -0.04273848]]\n"
     ]
    }
   ],
   "source": [
    "# Like any other supervised machine learning problem, we need to divide data into \n",
    "# 20% test set and 80% training set\n",
    "\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "\n",
    "X_train = word_averaging_list(X.wv,train_tokenized)\n",
    "X_test = word_averaging_list(X.wv,test_tokenized)\n",
    "\n",
    "y_train = train[0]\n",
    "y_test = test[0]\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 33.3333333333\n",
      "Decision Tree Accuracy: 20.7547169811\n",
      "Random Forest Accuracy: 35.2201257862\n",
      "Logistic Regression Accuracy: 30.8176100629\n",
      "SGD Classifier Accuracy: 30.8176100629\n",
      "Naive Bayes Accuracy: 30.8176100629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 36.4779874214\n"
     ]
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_train, y_train)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93  7]\n",
      " [46 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.93      0.78       100\n",
      "        True       0.65      0.22      0.33        59\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       159\n",
      "   macro avg       0.66      0.58      0.55       159\n",
      "weighted avg       0.66      0.67      0.61       159\n",
      "\n",
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print((accuracy_score(y_test, y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
