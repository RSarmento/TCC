{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Python: 3.6.3 (default, Oct  3 2017, 21:45:48) \n[GCC 7.2.0]\nNLTK: 3.4.4\nScikit-learn: 0.21.3\nPandas: 0.25.0\nNumpy: 1.17.0\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/audora/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "nltk.download('punkt')\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 793 entries, 0 to 792\nData columns (total 2 columns):\n0    793 non-null object\n1    793 non-null object\ndtypes: object(2)\nmemory usage: 12.5+ KB\nNone\n                0                                                  1\n0          outros  pretensa estadual deduz apel extrem esbarr ved...\n1           civil  embarg insist mesm razo recurs apresent oposic...\n2           civil  acorda ora recorr nao neg vigenc direit federa...\n3           civil  tribunal justic assent compreensa part det leg...\n4  administrativo  segund jurisprudenc superior tribunal justic a...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/dataset_multi.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "df.fillna('x', inplace=True)\n",
    "#df_classes_raw = pd.read_csv('data/classes_raw.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "8\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f9da9c01dd8>",
      "text/html": "<style  type=\"text/css\" >\n    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row0_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row1_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 73.0%, transparent 73.0%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row2_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 37.8%, transparent 37.8%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row3_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 27.4%, transparent 27.4%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row4_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 23.3%, transparent 23.3%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row5_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 22.2%, transparent 22.2%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row6_col0 {\n            width:  10em;\n             height:  80%;\n            background:  linear-gradient(90deg,#d65f5f 7.0%, transparent 7.0%);\n        }    #T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row7_col0 {\n            width:  10em;\n             height:  80%;\n        }</style><table id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row0\" class=\"row_heading level0 row0\" >civil</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row0_col0\" class=\"data row0 col0\" >271</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row1\" class=\"row_heading level0 row1\" >outros</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row1_col0\" class=\"data row1 col0\" >198</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row2\" class=\"row_heading level0 row2\" >administrativo</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row2_col0\" class=\"data row2 col0\" >103</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row3\" class=\"row_heading level0 row3\" >penal</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row3_col0\" class=\"data row3 col0\" >75</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row4\" class=\"row_heading level0 row4\" >tributário</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row4_col0\" class=\"data row4 col0\" >64</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row5\" class=\"row_heading level0 row5\" >constitucional</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row5_col0\" class=\"data row5 col0\" >61</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row6\" class=\"row_heading level0 row6\" >previdenciário</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row6_col0\" class=\"data row6 col0\" >20</td>\n            </tr>\n            <tr>\n                        <th id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9level0_row7\" class=\"row_heading level0 row7\" >empresarial</th>\n                        <td id=\"T_8b08f16e_be9e_11e9_8188_d05099a0e2b9row7_col0\" class=\"data row7 col0\" >1</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "\n",
    "classes = df[0]\n",
    "print(len(classes.value_counts()))\n",
    "classes.value_counts().to_frame().style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[4 1 1 1 0 2 5 5 4 4]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "793"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes\n",
    "encoder = LabelEncoder()\n",
    "classes = encoder.fit_transform(classes)\n",
    "\n",
    "print(classes[:10])\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0    pretensa estadual deduz apel extrem esbarr ved...\n1    embarg insist mesm razo recurs apresent oposic...\n2    acorda ora recorr nao neg vigenc direit federa...\n3    tribunal justic assent compreensa part det leg...\n4    segund jurisprudenc superior tribunal justic a...\n5    sobrest recurs especial ate julgament recurs e...\n6    inadmissivel exigenc recolh reu prisa requisit...\n7    dentr limit leg vez caracteriz reincidenc agra...\n8    sobr prescrica aca repetica indebit tributari ...\n9    tratas agrav instrument interpost contr decisa...\nName: 1, dtype: object\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Word2Vec(vocab=3183, size=100, alpha=0.025)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# uso de word2vec para a extração de features\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ementas_list = [word for word in ementas.iteritems()]\n",
    "ementas_list_list = []\n",
    "for doc in ementas_list:\n",
    "    ementas_list_list.append(doc[1].split())\n",
    "\n",
    "X = Word2Vec(ementas_list_list, min_count=2)\n",
    "X.wv.init_sims() # para inicializar model.vw.syn0norm, necessário para o cálculo da média da\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# funções para calcular a média vetorial das palavras de cada ementa\n",
    "import numpy as np\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        print(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# função para tokenizar as palavras com frequência maior que 2\n",
    "import nltk\n",
    "\n",
    "\n",
    "def w2v_tokenize_text(text):    \n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='portuguese'):\n",
    "        for word in nltk.word_tokenize(sent, language='portuguese'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "cannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\n",
      "cannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\ncannot compute similarity with no input %s []\n[[ 0.05816281  0.06925008  0.01058854 ... -0.05692833 -0.01062296\n  -0.01773864]\n [ 0.05668664  0.0714181   0.01187222 ... -0.05546273 -0.01052836\n  -0.00976634]\n [ 0.05447049  0.07175037  0.00836629 ... -0.05591553 -0.0118912\n  -0.0117317 ]\n ...\n [ 0.05938061  0.07013044  0.00956468 ... -0.05634766 -0.00976905\n  -0.01873341]\n [ 0.0533517   0.06857247  0.01570624 ... -0.05491859 -0.01532581\n  -0.00132969]\n [ 0.05760888  0.07024432  0.01076833 ... -0.05643673 -0.01084711\n  -0.01421217]]\n[[ 0.05365771  0.06937832  0.01495082 ... -0.05496734 -0.0116888\n  -0.0035093 ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.05472649  0.07125472  0.01385644 ... -0.05566638 -0.00925164\n  -0.00114947]\n ...\n [ 0.05599611  0.07081215  0.01287798 ... -0.05576077 -0.00990575\n  -0.00763242]\n [ 0.05683427  0.07244314  0.00698216 ... -0.05506735 -0.01335716\n  -0.01074267]\n [ 0.06099856  0.06944437  0.0087174  ... -0.05689148 -0.01175718\n  -0.03130387]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Like any other supervised machine learning problem, we need to divide data into \n",
    "# 20% test set and 80% training set\n",
    "\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "\n",
    "X_train = word_averaging_list(X.wv,train_tokenized)\n",
    "X_test = word_averaging_list(X.wv,test_tokenized)\n",
    "\n",
    "y_train = train[0]\n",
    "y_test = test[0]\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "K Nearest Neighbors Accuracy: 30.18867924528302\nDecision Tree Accuracy: 32.70440251572327\n",
      "Random Forest Accuracy: 37.10691823899371\nLogistic Regression Accuracy: 41.509433962264154\nSGD Classifier Accuracy: 17.61006289308176\n",
      "Naive Bayes Accuracy: 41.509433962264154\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Voting Classifier: Accuracy: 35.84905660377358\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_train, y_train)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                precision    recall  f1-score   support\n\nadministrativo       0.22      0.08      0.12        24\n         civil       0.43      0.81      0.56        63\nconstitucional       0.00      0.00      0.00        12\n        outros       0.15      0.16      0.15        25\n         penal       0.00      0.00      0.00        14\nprevidenciário       0.00      0.00      0.00         7\n    tributário       0.00      0.00      0.00        14\n\n      accuracy                           0.36       159\n     macro avg       0.11      0.15      0.12       159\n  weighted avg       0.23      0.36      0.26       159\n\n35.84905660377358\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/audora/tcc/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print((accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train: 427,427\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# usando undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy='majority', random_state=0)\n",
    "rus.fit(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "print(\"train: {},{}\".format(len(X_resampled),len(y_resampled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "K Nearest Neighbors Accuracy: 15.09433962264151\nDecision Tree Accuracy: 18.238993710691823\n",
      "Random Forest Accuracy: 20.125786163522015\nLogistic Regression Accuracy: 15.723270440251572\nSGD Classifier Accuracy: 15.09433962264151\nNaive Bayes Accuracy: 15.723270440251572\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Fazendo a mesma análisa usando undersampling\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Voting Classifier: Accuracy: 15.723270440251572\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_resampled, y_resampled)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                precision    recall  f1-score   support\n\nadministrativo       0.10      0.04      0.06        24\n         civil       0.00      0.00      0.00        63\nconstitucional       0.00      0.00      0.00        12\n        outros       0.16      0.96      0.28        25\n         penal       0.00      0.00      0.00        14\nprevidenciário       0.00      0.00      0.00         7\n    tributário       0.00      0.00      0.00        14\n\n      accuracy                           0.16       159\n     macro avg       0.04      0.14      0.05       159\n  weighted avg       0.04      0.16      0.05       159\n\n15.723270440251572\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/audora/tcc/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print((accuracy_score(y_test, y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-65cc7394",
   "language": "python",
   "display_name": "PyCharm (tcc)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}