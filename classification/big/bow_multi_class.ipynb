{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.3 (default, Oct  3 2017, 21:45:48) \n",
      "[GCC 7.2.0]\n",
      "NLTK: 3.4.4\n",
      "Scikit-learn: 0.21.3\n",
      "Pandas: 0.25.0\n",
      "Numpy: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1324772 entries, 0 to 1653761\n",
      "Data columns (total 2 columns):\n",
      "0    1324772 non-null object\n",
      "1    1324772 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 30.3+ MB\n",
      "None\n",
      "            0                                                  1\n",
      "0      outros  pretensa estadual deduz apel extrem esbarr ved...\n",
      "1       civil  embarg insist mesm razo recurs apresent oposic...\n",
      "2  processual  acorda ora recorr nao neg vigenc direit federa...\n",
      "3      outros  segund jurisprudenc superior tribunal justic a...\n",
      "4      outros  especial superior tribunal justic decid ser ne...\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/big/dataset_multi.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.9%, transparent 4.9%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.8%, transparent 4.8%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.7%, transparent 4.7%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row4_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.3%, transparent 4.3%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row5_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 3.2%, transparent 3.2%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row6_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 2.4%, transparent 2.4%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row7_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 1.8%, transparent 1.8%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row8_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 0.0%, transparent 0.0%);\n",
       "        }    #T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row9_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row0\" class=\"row_heading level0 row0\" >outros</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row0_col0\" class=\"data row0 col0\" >1043036</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row1\" class=\"row_heading level0 row1\" >previdenciário</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row1_col0\" class=\"data row1 col0\" >51518</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row2\" class=\"row_heading level0 row2\" >constitucional</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row2_col0\" class=\"data row2 col0\" >51225</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row3\" class=\"row_heading level0 row3\" >tributário</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row3_col0\" class=\"data row3 col0\" >50194</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row4\" class=\"row_heading level0 row4\" >processual</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row4_col0\" class=\"data row4 col0\" >46082</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row5\" class=\"row_heading level0 row5\" >administrativo</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row5_col0\" class=\"data row5 col0\" >34629</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row6\" class=\"row_heading level0 row6\" >penal</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row6_col0\" class=\"data row6 col0\" >26102</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row7\" class=\"row_heading level0 row7\" >civil</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row7_col0\" class=\"data row7 col0\" >19844</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row8\" class=\"row_heading level0 row8\" >ambiental</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row8_col0\" class=\"data row8 col0\" >1168</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9level0_row9\" class=\"row_heading level0 row9\" >internacional</th>\n",
       "                        <td id=\"T_29f6ce90_cdb3_11e9_9c7c_d05099a0e2b9row9_col0\" class=\"data row9 col0\" >974</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f34dc4605c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "classes = df[0]\n",
    "print(len(classes.value_counts()))\n",
    "classes.value_counts().to_frame().style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes em binário\n",
    "encoder = LabelEncoder()\n",
    "binary = encoder.fit_transform(classes)\n",
    "\n",
    "print(binary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pretensa estadual deduz apel extrem esbarr ved...\n",
      "1    embarg insist mesm razo recurs apresent oposic...\n",
      "2    acorda ora recorr nao neg vigenc direit federa...\n",
      "3    tribunal justic assent compreensa part det leg...\n",
      "4    segund jurisprudenc superior tribunal justic a...\n",
      "5    sobrest recurs especial ate julgament recurs e...\n",
      "6    inadmissivel exigenc recolh reu prisa requisit...\n",
      "7    dentr limit leg vez caracteriz reincidenc agra...\n",
      "8    sobr prescrica aca repetica indebit tributari ...\n",
      "9    tratas agrav instrument interpost contr decisa...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# criação do BOW (bag of words)\n",
    "all_words = []\n",
    "\n",
    "for ementa in ementas:\n",
    "    words = word_tokenize(ementa)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras: 4905\n",
      "Palavras mais comuns: [('nao', 1587), ('recurs', 724), ('lei', 633), ('art', 631), ('especial', 601), ('embarg', 593), ('n', 584), ('agrav', 555), ('ser', 430), ('tribunal', 418), ('regimental', 363), ('sumul', 354), ('dev', 346), ('acorda', 328), ('cort', 321)]\n"
     ]
    }
   ],
   "source": [
    "# Exibição do número total de palavras e as 15 mais comuns\n",
    "print('Número de palavras: {}'.format(len(all_words)))\n",
    "print('Palavras mais comuns: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso das 1500 palavras mais comuns como características\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretensa\n",
      "estadual\n",
      "deduz\n",
      "apel\n",
      "extrem\n",
      "esbarr\n",
      "vedaco\n",
      "cont\n",
      "sumul\n",
      "stj\n",
      "med\n",
      "necessari\n",
      "reexam\n",
      "conjunt\n",
      "faticoprobatori\n",
      "aut\n",
      "bem\n",
      "clausul\n",
      "contratu\n",
      "deslind\n",
      "controvers\n",
      "total\n",
      "inviavel\n",
      "agrav\n",
      "improv\n"
     ]
    }
   ],
   "source": [
    "# Função determina quais das 1500 palavras características estão contidas nas ementas\n",
    "\n",
    "def find_features(ementa):\n",
    "    words = word_tokenize(ementa)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Por exemplo\n",
    "features = find_features(ementas[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando à todas as ementas\n",
    "ementas_zip = list(zip(ementas, binary))\n",
    "zipped_list_1 = ementas_zip[:]\n",
    "zipped_list_2 = list(ementas_zip) \n",
    "\n",
    "# embaralhando lista\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(zipped_list_2)\n",
    "\n",
    "# chamando a função find_features para cada ementa\n",
    "featuresets = [(find_features(text), label) for (text, label) in ementas_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos conjuntos de característas em treinamento e teste usando sklean\n",
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 64.321608040201\n",
      "Decision Tree Accuracy: 78.39195979899498\n",
      "Random Forest Accuracy: 81.90954773869346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 77.88944723618091\n",
      "SGD Classifier Accuracy: 80.40201005025126\n",
      "Naive Bayes Accuracy: 72.8643216080402\n",
      "SVM Linear Accuracy: 76.88442211055276\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    nltk_model = SklearnClassifier(classifier)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 76.88442211055276\n"
     ]
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação de classe de label de predição para conjunto de teste\n",
    "\n",
    "txt_features_2, labels_2 = list(zip(*testing))\n",
    "txt_features_1, labels_1 = txt_features_2[:], labels_2[:]\n",
    "txt_features, labels = list(txt_features_2), list(labels_2)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.84       136\n",
      "           1       0.68      0.57      0.62        63\n",
      "\n",
      "    accuracy                           0.78       199\n",
      "   macro avg       0.75      0.72      0.73       199\n",
      "weighted avg       0.77      0.78      0.77       199\n",
      "\n",
      "76.88442211055276\n"
     ]
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "print(classification_report(labels, prediction))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
