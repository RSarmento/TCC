{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.3 (default, Oct  3 2017, 21:45:48) \n",
      "[GCC 7.2.0]\n",
      "NLTK: 3.4.4\n",
      "Scikit-learn: 0.21.3\n",
      "Pandas: 0.25.0\n",
      "Numpy: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9740 entries, (outros, 1484423) to (outros, 1535418)\n",
      "Data columns (total 2 columns):\n",
      "0    9740 non-null object\n",
      "1    9740 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 256.9+ KB\n",
      "None\n",
      "                                     0  \\\n",
      "0                                        \n",
      "outros         1484423          outros   \n",
      "constitucional 688167   constitucional   \n",
      "tributário     637931       tributário   \n",
      "ambiental      1098559       ambiental   \n",
      "administrativo 20853    administrativo   \n",
      "\n",
      "                                                                        1  \n",
      "0                                                                          \n",
      "outros         1484423  nao merec ser prov agrav instrument nao conseg...  \n",
      "constitucional 688167   entend turm sent ser cabivel antecipaca tutel ...  \n",
      "tributário     637931   mand seguranc objetiv compens integral valor r...  \n",
      "ambiental      1098559  atu magistr investigaca criminal orga garant l...  \n",
      "administrativo 20853    ausent question previ disposit leg cuj violaca...  \n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/big/dataset_multi.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "df = df.dropna()\n",
    "df = df.groupby(by=0).apply(lambda x: x.sample(df.groupby(by=0).size().min()))\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row4_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row5_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row6_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row7_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row8_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row9_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row0\" class=\"row_heading level0 row0\" >civil</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row0_col0\" class=\"data row0 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row1\" class=\"row_heading level0 row1\" >outros</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row1_col0\" class=\"data row1 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row2\" class=\"row_heading level0 row2\" >ambiental</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row2_col0\" class=\"data row2 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row3\" class=\"row_heading level0 row3\" >constitucional</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row3_col0\" class=\"data row3 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row4\" class=\"row_heading level0 row4\" >tributário</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row4_col0\" class=\"data row4 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row5\" class=\"row_heading level0 row5\" >previdenciário</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row5_col0\" class=\"data row5 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row6\" class=\"row_heading level0 row6\" >processual</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row6_col0\" class=\"data row6 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row7\" class=\"row_heading level0 row7\" >administrativo</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row7_col0\" class=\"data row7 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row8\" class=\"row_heading level0 row8\" >penal</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row8_col0\" class=\"data row8 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9level0_row9\" class=\"row_heading level0 row9\" >internacional</th>\n",
       "                        <td id=\"T_638f1dbe_ce40_11e9_bf5c_d05099a0e2b9row9_col0\" class=\"data row9 col0\" >974</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb75c1ae630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "classes = df[0]\n",
    "print(len(classes.value_counts()))\n",
    "classes.value_counts().to_frame().style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 9 1 0 0 1 9 6 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes em binário\n",
    "encoder = LabelEncoder()\n",
    "binary = encoder.fit_transform(classes)\n",
    "\n",
    "print(binary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outros          1484423    nao merec ser prov agrav instrument nao conseg...\n",
      "constitucional  688167     entend turm sent ser cabivel antecipaca tutel ...\n",
      "tributário      637931     mand seguranc objetiv compens integral valor r...\n",
      "ambiental       1098559    atu magistr investigaca criminal orga garant l...\n",
      "administrativo  20853      ausent question previ disposit leg cuj violaca...\n",
      "                268870     med concurs logr exit impetr ora apel prev vag...\n",
      "ambiental       959058     pesc lug interdit orga competent apetrech nao ...\n",
      "tributário      1072201    pretend agrav recurs modific decisa deix conde...\n",
      "penal           298797     encerr instruca criminal ja tend sid inquir te...\n",
      "ambiental       925454     compet justic federal process julg crim manute...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# criação do BOW (bag of words)\n",
    "all_words = []\n",
    "\n",
    "for ementa in ementas:\n",
    "    words = word_tokenize(ementa)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras: 16910\n",
      "Palavras mais comuns: [('nao', 18870), ('art', 9155), ('lei', 8795), ('n', 8317), ('recurs', 5642), ('ser', 5557), ('prov', 4984), ('dev', 4842), ('federal', 3841), ('part', 3630), ('agrav', 3354), ('direit', 3280), ('pod', 3235), ('public', 3233), ('conhec', 3006)]\n"
     ]
    }
   ],
   "source": [
    "# Exibição do número total de palavras e as 15 mais comuns\n",
    "print('Número de palavras: {}'.format(len(all_words)))\n",
    "print('Palavras mais comuns: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso das 1500 palavras mais comuns como características\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nao\n",
      "merec\n",
      "ser\n",
      "prov\n",
      "agrav\n",
      "instrument\n",
      "conseg\n",
      "infirm\n",
      "fundament\n",
      "despach\n",
      "denegatori\n",
      "process\n",
      "recurs\n",
      "revist\n",
      "conhec\n",
      "desprov\n"
     ]
    }
   ],
   "source": [
    "# Função determina quais das 1500 palavras características estão contidas nas ementas\n",
    "\n",
    "def find_features(ementa):\n",
    "    words = word_tokenize(ementa)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Por exemplo\n",
    "features = find_features(ementas[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando à todas as ementas\n",
    "ementas_zip = list(zip(ementas, binary))\n",
    "zipped_list_1 = ementas_zip[:]\n",
    "zipped_list_2 = list(ementas_zip) \n",
    "\n",
    "# embaralhando lista\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(zipped_list_2)\n",
    "\n",
    "# chamando a função find_features para cada ementa\n",
    "featuresets = [(find_features(text), label) for (text, label) in ementas_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos conjuntos de característas em treinamento e teste usando sklean\n",
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7305\n",
      "2435\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 28.952772073921974\n",
      "Decision Tree Accuracy: 47.80287474332649\n",
      "Random Forest Accuracy: 62.83367556468173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audora/tcc/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/audora/tcc/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 57.57700205338809\n",
      "SGD Classifier Accuracy: 53.38809034907598\n",
      "Naive Bayes Accuracy: 55.93429158110883\n",
      "SVM Linear Accuracy: 53.55236139630391\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    nltk_model = SklearnClassifier(classifier)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 53.55236139630391\n"
     ]
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação de classe de label de predição para conjunto de teste\n",
    "\n",
    "txt_features_2, labels_2 = list(zip(*testing))\n",
    "txt_features_1, labels_1 = txt_features_2[:], labels_2[:]\n",
    "txt_features, labels = list(txt_features_2), list(labels_2)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44       245\n",
      "           1       0.77      0.81      0.79       263\n",
      "           2       0.50      0.49      0.49       242\n",
      "           3       0.59      0.44      0.50       252\n",
      "           4       0.82      0.77      0.79       257\n",
      "           5       0.60      0.69      0.64       250\n",
      "           6       0.66      0.70      0.68       221\n",
      "           7       0.67      0.71      0.69       240\n",
      "           8       0.35      0.31      0.33       212\n",
      "           9       0.58      0.57      0.58       253\n",
      "\n",
      "    accuracy                           0.60      2435\n",
      "   macro avg       0.60      0.60      0.59      2435\n",
      "weighted avg       0.60      0.60      0.60      2435\n",
      "\n",
      "53.55236139630391\n"
     ]
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(labels, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
