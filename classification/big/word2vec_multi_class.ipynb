{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.3 (default, Oct  3 2017, 21:45:48) \n",
      "[GCC 7.2.0]\n",
      "NLTK: 3.4.4\n",
      "Scikit-learn: 0.21.3\n",
      "Pandas: 0.25.0\n",
      "Numpy: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9740 entries, (constitucional, 213470) to (outros, 646757)\n",
      "Data columns (total 2 columns):\n",
      "0    9740 non-null object\n",
      "1    9740 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 256.9+ KB\n",
      "None\n",
      "                                    0  \\\n",
      "0                                       \n",
      "constitucional 213470  constitucional   \n",
      "administrativo 993055  administrativo   \n",
      "               183316  administrativo   \n",
      "ambiental      920317       ambiental   \n",
      "constitucional 802969  constitucional   \n",
      "\n",
      "                                                                       1  \n",
      "0                                                                         \n",
      "constitucional 213470  nao ha qualqu inconstitucional formal lei n in...  \n",
      "administrativo 993055  fat autenticaco banc nao ser perfeit legiv tod...  \n",
      "               183316  aca mandamental pressupo prov preconstitu nao ...  \n",
      "ambiental      920317  crim pesc proib lei art inci depend norm suple...  \n",
      "constitucional 802969  cf exprim tod eficac jurid nel cont mostrandos...  \n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/big/dataset_multi.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "df = df.dropna()\n",
    "df = df.groupby(by=0).apply(lambda x: x.sample(df.groupby(by=0).size().min()))\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row4_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row5_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row6_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row7_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row8_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row9_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row0\" class=\"row_heading level0 row0\" >civil</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row0_col0\" class=\"data row0 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row1\" class=\"row_heading level0 row1\" >administrativo</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row1_col0\" class=\"data row1 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row2\" class=\"row_heading level0 row2\" >tributário</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row2_col0\" class=\"data row2 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row3\" class=\"row_heading level0 row3\" >constitucional</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row3_col0\" class=\"data row3 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row4\" class=\"row_heading level0 row4\" >penal</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row4_col0\" class=\"data row4 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row5\" class=\"row_heading level0 row5\" >outros</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row5_col0\" class=\"data row5 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row6\" class=\"row_heading level0 row6\" >previdenciário</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row6_col0\" class=\"data row6 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row7\" class=\"row_heading level0 row7\" >internacional</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row7_col0\" class=\"data row7 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row8\" class=\"row_heading level0 row8\" >ambiental</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row8_col0\" class=\"data row8 col0\" >974</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9level0_row9\" class=\"row_heading level0 row9\" >processual</th>\n",
       "                        <td id=\"T_c258daf4_ce3d_11e9_bf5c_d05099a0e2b9row9_col0\" class=\"data row9 col0\" >974</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe7cc3e69e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "\n",
    "classes = df[0]\n",
    "print(len(classes.value_counts()))\n",
    "classes.value_counts().to_frame().style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 0 1 3 7 0 3 1 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9740"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes\n",
    "encoder = LabelEncoder()\n",
    "classes = encoder.fit_transform(classes)\n",
    "\n",
    "print(classes[:10])\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constitucional  213470    nao ha qualqu inconstitucional formal lei n in...\n",
      "administrativo  993055    fat autenticaco banc nao ser perfeit legiv tod...\n",
      "                183316    aca mandamental pressupo prov preconstitu nao ...\n",
      "ambiental       920317    crim pesc proib lei art inci depend norm suple...\n",
      "constitucional  802969    cf exprim tod eficac jurid nel cont mostrandos...\n",
      "previdenciário  275243    divergenc jurisprudencial comprov inteligenc a...\n",
      "administrativo  243660    hipotes juiz quo garant agrav candidat inscrit...\n",
      "constitucional  139928    nao cab superior tribunal justic aprec mat ind...\n",
      "ambiental       27160     federal competenc process julg aca penal fund ...\n",
      "previdenciário  995418    federal assegur assistenc social necessit inde...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=9979, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# uso de word2vec para a extração de features\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ementas_list = [word for word in ementas.iteritems()]\n",
    "ementas_list_list = []\n",
    "for doc in ementas_list:\n",
    "    ementas_list_list.append(doc[1].split())\n",
    "\n",
    "X = Word2Vec(ementas_list_list, min_count=2, window=5, workers=4)\n",
    "X.wv.init_sims() # para inicializar model.vw.syn0norm, necessário para o cálculo da média da\n",
    "print(X)\n",
    "X.save('big_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# funções para calcular a média vetorial das palavras de cada ementa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        # print(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# função para tokenizar as palavras com frequência maior que 2\n",
    "import nltk\n",
    "\n",
    "\n",
    "def w2v_tokenize_text(text):    \n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='portuguese'):\n",
    "        for word in nltk.word_tokenize(sent, language='portuguese'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 7792,7792\n",
      "test: 1948,1948\n"
     ]
    }
   ],
   "source": [
    "# Like any other supervised machine learning problem, we need to divide data into \n",
    "# 20% test set and 80% training set\n",
    "\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r[1]), axis=1).values\n",
    "\n",
    "# X = Word2Vec.load('big_word2vec.model')\n",
    "X_train = word_averaging_list(X.wv,train_tokenized)\n",
    "X_test = word_averaging_list(X.wv,test_tokenized)\n",
    "\n",
    "y_train = train[0]\n",
    "y_test = test[0]\n",
    "\n",
    "print(\"train: {},{}\".format(len(X_train),len(y_train)))\n",
    "print(\"test: {},{}\".format(len(X_test),len(y_test)))\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 44.455852156057496\n",
      "Decision Tree Accuracy: 33.2135523613963\n",
      "Random Forest Accuracy: 51.28336755646817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audora/tcc/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 49.58932238193018\n",
      "SGD Classifier Accuracy: 49.58932238193018\n",
      "Naive Bayes Accuracy: 49.332648870636554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 51.48870636550308\n"
     ]
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_train, y_train)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "administrativo       0.36      0.32      0.34       195\n",
      "     ambiental       0.70      0.73      0.72       203\n",
      "         civil       0.43      0.38      0.40       192\n",
      "constitucional       0.41      0.42      0.42       189\n",
      " internacional       0.63      0.62      0.63       195\n",
      "        outros       0.55      0.48      0.52       190\n",
      "         penal       0.60      0.60      0.60       193\n",
      "previdenciário       0.60      0.67      0.63       199\n",
      "    processual       0.30      0.35      0.32       196\n",
      "    tributário       0.55      0.57      0.56       196\n",
      "\n",
      "      accuracy                           0.51      1948\n",
      "     macro avg       0.51      0.51      0.51      1948\n",
      "  weighted avg       0.51      0.51      0.51      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 7710,7710\n"
     ]
    }
   ],
   "source": [
    "# usando undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "rus.fit(X_train, y_train)\n",
    "X_resampled, y_resampled = rus._fit_resample(X_train, y_train)\n",
    "print(\"train: {},{}\".format(len(X_resampled),len(y_resampled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Fazendo a mesma análisa usando undersampling\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=200),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=200),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_resampled, y_resampled)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (tcc)",
   "language": "python",
   "name": "pycharm-65cc7394"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
