{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.3 (default, Oct  3 2017, 21:45:48) \n",
      "[GCC 7.2.0]\n",
      "NLTK: 3.4.4\n",
      "Scikit-learn: 0.21.3\n",
      "Pandas: 0.25.0\n",
      "Numpy: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9740 entries, (administrativo, 214401) to (tributário, 191815)\n",
      "Data columns (total 2 columns):\n",
      "0    9740 non-null object\n",
      "1    9740 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 256.9+ KB\n",
      "None\n",
      "                                     0  \\\n",
      "0                                        \n",
      "administrativo 214401   administrativo   \n",
      "previdenciário 876919   previdenciário   \n",
      "outros         1288379          outros   \n",
      "previdenciário 656233   previdenciário   \n",
      "administrativo 664101   administrativo   \n",
      "\n",
      "                                                                        1  \n",
      "0                                                                          \n",
      "administrativo 214401   indigit alegaca funcion ilegal mencion radiodi...  \n",
      "previdenciário 876919   levant rend inicial auxiliodoenc segur acomet ...  \n",
      "outros         1288379  part recorrent obrig efetu deposit legal integ...  \n",
      "previdenciário 656233   novembr efet restabelec refer categor exclu de...  \n",
      "administrativo 664101   julg profer tribunal quo nao possu contradica ...  \n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/big/dataset_multi.txt', header=None, encoding='utf-8', sep='\\t')\n",
    "df = df.dropna()\n",
    "df = df.groupby(by=0).apply(lambda x: x.sample(df.groupby(by=0).size().min()))\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambiental         974\n",
      "constitucional    974\n",
      "administrativo    974\n",
      "internacional     974\n",
      "outros            974\n",
      "penal             974\n",
      "processual        974\n",
      "civil             974\n",
      "previdenciário    974\n",
      "tributário        974\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 7 5 7 0 3 7 7 5 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes em binário\n",
    "encoder = LabelEncoder()\n",
    "binary = encoder.fit_transform(classes)\n",
    "\n",
    "print(binary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "administrativo  214401     indigit alegaca funcion ilegal mencion radiodi...\n",
      "previdenciário  876919     levant rend inicial auxiliodoenc segur acomet ...\n",
      "outros          1288379    part recorrent obrig efetu deposit legal integ...\n",
      "previdenciário  656233     novembr efet restabelec refer categor exclu de...\n",
      "administrativo  664101     julg profer tribunal quo nao possu contradica ...\n",
      "constitucional  1284883    caracteriz contrat trabalh evidenc empreg publ...\n",
      "previdenciário  184184     calcul rend mensal inicial benefici dev ser ut...\n",
      "                837998     autor aposentador invalidez revist cancel proc...\n",
      "outros          790434     fixaca penabas sao analis oit circunstanc judi...\n",
      "processual      340685     present entend superior tribunal justic credor...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# The following script uses the bag of words model to convert text documents into \n",
    "# corresponding numerical features:\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X = vectorizer.fit_transform(ementas).toarray()\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#  The following script directly convert text documents into TFIDF feature values \n",
    "# (without first converting documents to bag of words features)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X = tfidfconverter.fit_transform(ementas).toarray()\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.06588102 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Like any other supervised machine learning problem, we need to divide data into \n",
    "# 20% test set and 80% training set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binary, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 16.27310061601643\n",
      "Decision Tree Accuracy: 47.84394250513347\n",
      "Random Forest Accuracy: 62.83367556468173\n",
      "Logistic Regression Accuracy: 61.139630390143736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Modelos para treinar\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=200),\n",
    "#     SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "#     MultinomialNB(),\n",
    "#     SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, classifier in models:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 61.90965092402464\n"
     ]
    }
   ],
   "source": [
    "# Classificador por votos\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced'),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    SGDClassifier(max_iter = 100, tol=1e-3),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1)\n",
    "votingClassifier.fit(X_train, y_train)\n",
    "y_pred = votingClassifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   6  30  15   0   7   5  13  14   8]\n",
      " [  8 147   5   4   2   3  19   2   4   0]\n",
      " [ 32   6  93   6   4  16   5   3  23   4]\n",
      " [ 22   2   7  95   1  15   6  12   5  23]\n",
      " [  2   6   7   0 171   4  27   1   1   2]\n",
      " [ 12   2  16  10   1 117  11   3   7   5]\n",
      " [  5   4   3   3  15   8 151   0   1   2]\n",
      " [ 12   1   5   4   0  16   0 151   7   3]\n",
      " [ 21   3  21  13   0   3   1  25  58  38]\n",
      " [  9   3   8  28   0   2   2   1  21 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.48      0.45       188\n",
      "           1       0.82      0.76      0.79       194\n",
      "           2       0.48      0.48      0.48       192\n",
      "           3       0.53      0.51      0.52       188\n",
      "           4       0.88      0.77      0.82       221\n",
      "           5       0.61      0.64      0.62       184\n",
      "           6       0.67      0.79      0.72       192\n",
      "           7       0.72      0.76      0.74       199\n",
      "           8       0.41      0.32      0.36       183\n",
      "           9       0.61      0.64      0.63       207\n",
      "\n",
      "    accuracy                           0.62      1948\n",
      "   macro avg       0.61      0.61      0.61      1948\n",
      "weighted avg       0.62      0.62      0.62      1948\n",
      "\n",
      "61.90965092402464\n"
     ]
    }
   ],
   "source": [
    "# relatório de classificação\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
