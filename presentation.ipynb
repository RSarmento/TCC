{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.2 (default, Jan 10 2019, 23:51:51) \n",
      "[GCC 8.2.1 20181127]\n",
      "NLTK: 3.4.1\n",
      "Scikit-learn: 0.21.2\n",
      "Pandas: 0.24.2\n",
      "Numpy: 1.16.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 2 columns):\n",
      "0    793 non-null bool\n",
      "1    793 non-null object\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 7.0+ KB\n",
      "None\n",
      "       0                                                  1\n",
      "0  False  mand seguranc inexecuca contrat sanca afast re...\n",
      "1  False  respons civil acid aere decretol n dol event r...\n",
      "2  False  process civil intimaca art  cpc irregular nao ...\n",
      "3  False  process civil honorari execuca legitim part su...\n",
      "4  False  administr serv publ artig lei artig  lei revog...\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('ementas_acordaos', header=None, encoding='utf-8', sep='\\t')\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    466\n",
      "True     327\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verificação das classes dos acórdãos\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convertendo classes em binário\n",
    "encoder = LabelEncoder()\n",
    "binary = encoder.fit_transform(classes)\n",
    "\n",
    "print(binary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    mand seguranc inexecuca contrat sanca afast re...\n",
      "1    respons civil acid aere decretol n dol event r...\n",
      "2    process civil intimaca art  cpc irregular nao ...\n",
      "3    process civil honorari execuca legitim part su...\n",
      "4    administr serv publ artig lei artig  lei revog...\n",
      "5    impost sobr serv is arrend mercantil incidenc ...\n",
      "6    petica receb habe corpu process penal art codi...\n",
      "7    penal process penal recurs espec art  incis ar...\n",
      "8    tribut sujeit lanc homologaca praz prescric le...\n",
      "9    transport intermunicip licitaca aca anulat ind...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# criação da lista de ementas\n",
    "ementas = df[1]\n",
    "print(ementas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# create bag-of-words\n",
    "all_words = []\n",
    "\n",
    "for ementa in ementas:\n",
    "    words = word_tokenize(ementa)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 4908\n",
      "Most common words: [('nao', 1736), ('recurs', 1121), ('agrav', 1018), ('art', 888), ('espec', 887), ('embarg', 847), ('lei', 818), ('process', 770), ('a', 747), ('regiment', 646), ('e', 640), ('sumul', 608), ('civil', 561), ('tribun', 498), ('prov', 486)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mand\n",
      "seguranc\n",
      "inexecuca\n",
      "contrat\n",
      "sanca\n",
      "afast\n",
      "reexam\n",
      "prov\n",
      "clausul\n",
      "sumul\n",
      "stj\n",
      "pretensa\n",
      "estad\n",
      "deduz\n",
      "apel\n",
      "extr\n",
      "esb\n",
      "vedaco\n",
      "cont\n",
      "med\n",
      "necessari\n",
      "conjunt\n",
      "faticoprobatori\n",
      "aut\n",
      "bem\n",
      "deslind\n",
      "controvers\n",
      "e\n",
      "total\n",
      "invia\n",
      "agrav\n",
      "improv\n"
     ]
    }
   ],
   "source": [
    "# The find_features function will determine which of the 1500 word features are contained in the ementas\n",
    "def find_features(ementa):\n",
    "    words = word_tokenize(ementa)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Lets see an example!\n",
    "features = find_features(ementas[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do it for all the messages\n",
    "ementas_zip = list(zip(ementas, binary))\n",
    "zipped_list_1 = ementas_zip[:]\n",
    "zipped_list_2 = list(ementas_zip) \n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(zipped_list_2)\n",
    "\n",
    "# call find_features function for each ementa\n",
    "featuresets = [(find_features(text), label) for (text, label) in ementas_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 83.91959798994975\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 58.291457286432156\n",
      "Decision Tree Accuracy: 85.92964824120602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 86.4321608040201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 84.42211055276381\n",
      "SGD Classifier Accuracy: 82.41206030150754\n",
      "Naive Bayes Accuracy: 72.36180904522614\n",
      "SVM Linear Accuracy: 83.91959798994975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 83.91959798994975\n"
     ]
    }
   ],
   "source": [
    "# Ensemble methods - Voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "zipped_models_1 = models[:]\n",
    "zipped_models_2 = list(models)\n",
    "\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = zipped_models_2, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class label prediction for testing set\n",
    "txt_features_2, labels_2 = list(zip(*testing))\n",
    "txt_features_1, labels_1 = txt_features_2[:], labels_2[:]\n",
    "txt_features, labels = list(txt_features_2), list(labels_2)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       117\n",
      "           1       0.83      0.78      0.81        82\n",
      "\n",
      "    accuracy                           0.84       199\n",
      "   macro avg       0.84      0.83      0.84       199\n",
      "weighted avg       0.84      0.84      0.84       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
